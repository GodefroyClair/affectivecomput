---
title: "Presentation graphiques pour l’analyse de données"
subtitle: "comment améliorer l'étiquetage des cartes de Kohonen"
author: "Godefroy Clair"
date: "28 août 2016"
output:
  pdf_document:
    includes:
      in_header: ../style/header.tex 
    fig_caption: yes
    latex_engine: xelatex
    number_sections: yes
    toc: yes
    toc_depth: 3
  html_document:
    css: ../style/simple-report.style.css
    number_sections: yes
    toc: yes
  word_document: default
---

```{r, include=FALSE}
df_type <- "centered" #"scaled" or "not_modified"
DEBUG <- F
black_frame <- rgb(.0, .0, .0)
no_frame <- rgb(1, 1, 1)
b_rad <- T
list.expe.selec <- c("AB", "CLP", "CW", "DA", "PCo", "PCo2", "PCo3", "DE")
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(plyr)
library(ggplot2)
library(gtable)
library(kohonen)
library(tidyr)
library(signal)
library(dplyr)
library(purrr)
library(testthat)
library(stringr)
library(ggradar)
library(purrr)
library(reshape2)
library(lubridate)
library(data.table)
#instal ggradar : devtools::install_github("ricardo-bion/ggradar", dependencies=TRUE)
# configured to work on a Mac, change directory to Unix or Windows
#download.file("https://dl.dropboxusercontent.com/u/2364714/airbnb_ttf_fonts/Circular Air-Light 3.46.45 PM.ttf", "/Library/Fonts/Circular Air-Light 3.46.45 PM.ttf", method="curl")
#extrafont::font_import(pattern = 'Circular', prompt=FALSE)
suppressPackageStartupMessages(library(dplyr))
library(scales)
theme_set(theme_bw(24))
```

#Episode précédent : le nettoyage des données 

Pour arriver à l'étape de l'étiquetage des données, un long travail préalable a été nécessaire...
Ce travail est constitué de trois phases :

- l'importation de données "valides".
- le nettoyage des données.
- la décomposition des données en information.
- l'apprentissage statistique grâce aux cartes de Kohonen dites "auto-organisatrices".

## Importation

Il a fallu choisir les expériences dont les données étaient utilisables. Pour cela, un travail d'observation et de questionnement a été fait (voir rapport "rcp209_2").

## Le nettoyage

Le nettoyage a surtout porté sur une variable : la respiration. Ce choix est en partie du à un manque de temps mais aussi du fait de la qualité de cette mesure qui rendait peu exploitable les données brutes de respiration.
On peut dire que le travail fait sur la respiration était plus urgent que le nettoyage des autres données et en même temps un exemple du travail à réaliser sur les autres variables...
On peut apparenter le travail réalisé ici à celui d'un detective : sans connaissance prélable, armé uniquement de données et d'outils de visualisation, chercher à données sens aux différentes régularités et irréguralités que l'on observe dans les données.

## La décomposition

Ce travail est indissociable du travail de nettoyage : le nettoyage nous a amené à trouver dans les données différents phénomènes simples qu'il a fallu extraire des données brutes.
Par exemple, dans un certain nombre d'expériences, il y a un temps pendant laquelle la ceinture mesurant la respiration semble se déplacer vers la taille est la plus fine. 
Nous avons donc du "extraire" cet effet. Plusiseurs options ont été envisagées (regression exponentiel, polynomiale, par fenêtre...) mais finalement appliquer un filtre passe-bas a donné les meilleurs résultats.
GRAPHIQUE RESULTAT
Un autre effet à prendre en compte, le caractère cyclique des données qui recèle de nombreuses informations : la fréquence de la respiration et surtout son évolution (le changement de durée d'un cycle de respiration), l'amplitude, ...
GRAPHS
Il y a aussi l'existence d'un bruit dans la mesure qu'il faut nettoyer. Là encore, les filtres de Fourrier (passe-bas cette fois) permettent de supprimer ces phénomènes parasitaires dans la recherche d'états émotionnels
AJOUTER DES GRAPHS

GRAPHIQUE DES CAS D'APPRENTISSAGE DS LA MESURE DE RESPIRATION




###Réflexion sur cette décomposition

La question de savoir s'il faut décomposer une variable en amont du travail d'apprentissage est une question complexe dans le cadre des apprentissages non-supervisées. Elle peut être considérée comme une forme d'assistance au travail des cartes de Kohonen alors que, dans l'idéale, l'algorithme devrait justement permettre de distinguer les différents phénomènes. En un sens, on s'éloigne des canons de l'apprentissage non-supervisée en introduisant plusieurs hypothèses apriori alors que l'idée de ces algorithmes est de les minimiser au maximum.
Tout ceci est vrai mais on peut avancer deux arguments : 

- D'abord il est inutile de demander à l'aglorithme des phénomènes que l'on peut observer "à l'oeil nu" : on perdrait de précieuses ressources de calcul dans ce travail. 
- Mais surtout, c'est l'essence même du travail de nettoyage  au sens large (dont fait partie la décomposition des phénomènes cachés dans les données) que de faire des hypothèses basées sur visualisation et de modifier les données en conséquence. Aucun travail d'apprentissage statistique ne peut se passer de ce travail déductif préalable sur les données qui doit aboutir à leur modification (s'appuyant sur des inférences).

Par contre, là où ce travail doit être amélioré, c'est sur la question de comment prendre en compte les conséquences de ce nettoyage. En effet, on introduit un biais potentiel puisque les variables issues de la décomposition vont être prises en compte dans les cartes de Kohonen selon une pondération qui est liées à la métrique choisie. Or, cette métrique reflète souvent plus l'hétérogénéité des données suivant chaque variable que leur valeur intrinsèque. Par exemple, avec la métrique basée sur les normes euclidiennes, les variables montrant A FINIR (CITER travaux Anastase)

En un sens dans l'état actuel, nous restons au milieu du gué : nous introduisons des hypothèses apriori qui ont des conséquences sur le résultat mais nous laissons au hasard le choix de comment ces hypothèses influencent le calcul.
Des travaux récents [CHRARANTONIS??] ont cherché à répondre à cette question en introduisant de nouvelles métriques....

## L'apprentissage statistique : les cartes de Kohonen

Une fois, les données décomposées en variables réputées, on peut lancer l'algorithme des cartes de Kohonen.

### Les résultats de l'apprentissage

Une difficulté est survenu du fait que l'apprentissage par défaut amené à un courbe d'apprentissage "coudée". Ce coude signifie généralement que l'apprentissage s'arrête à un minimum local... 

Finalement, on voit que l'on passe le coude, même s'il en reste un petit...

```{r, echo =F, message = F, cache = T}
load(verbose = T, file = "../data/som1.RDa")
load(verbose = T, file = "../data/som2.RDa")
load(verbose = T, file = "../data/som3.RDa")
load(verbose = T, file = "../data/df_stat_scale_scale.RDa")
load(verbose = T, file = "../data/df_stat_center_scale.RDa")
load(verbose = T, file = "../data/df_stat_scaled.RDa")
load(verbose = T, file = "../data/df_selec.RDa")
#plot of the learning curve of kohonen maps (distance )
#a changer
#df_stat <- df_stat_scaled #df_stat_scaled ou df_stat_scale_scale
if(df_type == "scaled") {
  df_stat <- df_stat_scaled
  som <- som1 #som1 ou som2
} else if (df_type == "not_modif") {
  df_stat <- df_stat_scale_scale
  som <- som2 #som1 ou som2
} else if (df_type == "centered") {
  df_stat <- df_stat_scale_scale
  som <- som3 #som1 ou som2 ou som3
}
```


```{r changes_map, echo =F, message = F, cache = T, fig.height=5.5, fig.width=5.5, fig.cap = "carte de l'apprentissage"}
plot(som, type="changes", main="distance moy. des réf. aux données par itération")
```

La carte suivante nous indique le nombre de données captées par chaque neurone.

```{r count_map, echo =F, cache = T, fig.height=5.5, fig.width=5.5, fig.cap = "carte de comptage des données par référents"}
plot(som, type="count", main= "nb de données captées à la fin de l'itération")

```

Celle-ci nous indique la distance des données à chaque référent. Elle indique donc si les données sont proches entre elles (car un référent mesure pour chaque variable la moyenne des données qu'il a collectées)

```{r quality_map, echo =F, cache = T, fig.height=5.5, fig.width=8.5, fig.cap = "carte de qualité"}
#obtenir un dégradé de couleurs de bleu à rouge
coolBlueHotRed <- function(n, alpha = 1) {rainbow(n, end=4/6, alpha=alpha)[n:1]}
plot(som, type="quality", palette.name = coolBlueHotRed, main = "distance moyenne des données aux neurones")
```
\newpage

### Quelques autres graphiques standards

Les graphiques suivants sont des graphiques dit "heatmap" pour chaque variable : ils permettent de voir les zones où cette variable est plus élevée ou au contraire plus basse.

```{r hm_transpi, echo =F, cache = T, fig.height=5.5, fig.width=5.5, fig ="heatmap"}
#TODO : heatmap par variable
plot(som, type = "property", property = som$codes[,1], main="activité életro-dermale", palette.name=coolBlueHotRed)
```


```{r hm_temp, echo =F, cache = T, fig.height=5.5, fig.width=5.5, fig.cap = "heatmap"}
plot(som, type = "property", property = som$codes[,2], main="température", palette.name=coolBlueHotRed)
```

```{r hm_freq_card, echo =F, cache = T, fig.height=5.5, fig.width=5.5, fig.cap = "heatmap"}
plot(som, type = "property", property = som$codes[,3], main="fréquence cardiaque", palette.name=coolBlueHotRed)
```

```{r hm_respi, echo =F, cache = T, fig.height=5.5, fig.width=5.5, fig.cap = "heatmap"}
plot(som, type = "property", property = som$codes[,4], main="respiration \"nettoyée\"", palette.name=coolBlueHotRed)
```

```{r hm_trend_resp, echo =F, cache = T, fig.height=5.5, fig.width=5.5, fig.cap = "heatmap"}
plot(som, type = "property", property = som$codes[,5], main="trend de la respiration", palette.name=coolBlueHotRed)
```


```{r hm_max_resp, echo =F, cache = T, fig.height=5.5, fig.width=5.5, fig.cap = "heatmap"}
plot(som, type = "property", property = som$codes[,6], main="max par periode respi", palette.name=coolBlueHotRed)
```

```{r hm_min_resp, echo =F, cache = T, fig.height=5.5, fig.width=5.5, fig.cap = "heatmap"}
plot(som, type = "property", property = som$codes[,7], main="min par periode respi", palette.name=coolBlueHotRed)
```

```{r hm_dur_resp, echo =F, cache = T, fig.height=5.5, fig.width=5.5, fig.cap = "heatmap"}
plot(som, type = "property", property = som$codes[,8], main="duree periodes respi", palette.name=coolBlueHotRed)
```

# Les nouveaux graphiques

L'idée est de reprendre la carte des "codes" disponibles avec la bibliothèque standard de Kohonen mais en utilisant la grammaire des graphiques et en offrant ainsi plus de flexibilité.
Ces graphiques ont pour but de faciliter la reconnaissance de régularités dans les cartes en proposant différents "histoires" : pour chaque graphique les ésthétiques et les formes géométriques doivent aider à rapprocher différentes facettes des données. 

## Les graphiques de type "multi-radars" et "multi-bar"

Les graphiques multi-radars, multi-bar, etc. permettent d'observer les valeurs des variable pour chaque référent en même temps. Pour chaque référent, chaque variable est représenté par une figure géométrique ("camembert", rayon, barre...) de couleur différente. Nous présentons différentes variantes : le premier est le plus classique, l'angle de chaque camembert est fixé et son aire est donnée par la valeur de la variable, le deuxième est basé sur un graphique de type "radar" : chaque variable est associée à la longueur d'un segment partant du centre. Le dernier graphique est plus classique : il s'agit d'un graphique en bâton. 

\newgeometry{left = 0cm, right = 0cm, top = 1cm, bottom = 3cm}
\newpage
\blandscape
```{r prep_graph_radar, echo =F, cache = b_rad, fig.height=8.5, fig.width=8.5}
#limit the nb of neurones we are working on to fasten the graph making process
#nb_neur has to be 300 in the end
nb_neur <- 900
nb_var <- 8
#make a df with the value of the variables associated with each neurone and the id of the neurone (id_neur)
#it is easier to rescale everything to ratio ([0-1]) with rescale
df_codes <- data.frame(som$codes) %>% add_rownames(var = "id_neur")  %>% 
  mutate_each(funs(rescale), -id_neur)  %>% head(nb_neur)
#id_neur needs to be numeric
df_codes$id_neur <- as.numeric(df_codes$id_neur)

#replace min_per_period by its opposite for coherence of graph
df_codes <- df_codes %>% 
  mutate(min_per_pd_opp = min_per_period) %>% 
  select(id_neur, activite.electrodermale, temperature, frequence.cardiaque, respi_clean_hl, trend, max_per_period, min_per_pd_opp, period_duration)

# to be able to use some of the ggplot::geom_XXX(), we need to untidy the data
melted_radar <- melt(df_codes, id = "id_neur")

#we build the label such that each facetted graph has a number associated to it
##!! this is a patch, there must be a way to do this BETTER !!
base_rep <- 1:nb_neur
rep <- rep("", nb_var - 1)
lab_rep <- purrr::map(base_rep, function(ele) { c(ele, rep)}) %>% unlist()
#ann_text <- data.frame(x=1.25, y=5, lab = as.character(lab_rep))

#titre des graphiques
base_titre <- "Carte d'identité des référents"

#theme that are used for the multiradar plot
radar_theme <-  theme(panel.margin.x = unit(0, "lines"), panel.margin.y = unit(0, "lines"), panel.border = element_rect(colour = no_frame, fill=NA, size=.5),
        axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(),
        axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank(),
        strip.background = element_blank(), strip.text.x = element_blank(),
        legend.title = element_text(colour="black", size=5,  face="bold"),
        legend.text = element_text(colour="black", size=5),
        legend.key = element_rect(size = 1),
        title = element_text(color = "blue", size =6, face = "bold"))

```
\elandscape
\restoregeometry

\newgeometry{left=0cm, right=0cm, bottom=3cm}
\newpage
\blandscape

```{r polar_graph, echo =F, cache = b_rad, fig.height=8.5, fig.width=10.5,fig.cap="carte de l'identité des neurones", out.width="1\\paperwidth"}
#length
ggplot(melted_radar, aes(x = variable, y = value, fill = variable)) %+% 
  facet_wrap( ~ id_neur, ncol = 30)  %+% 
  geom_bar(stat="identity",position="dodge") %+%
  ylim(0,1) %+%
  geom_text(aes(x = 1.5, y = 1, label = lab_rep), colour="black", size = 1, inherit.aes=F) %+%
  coord_polar(start = 0)  %+%
  radar_theme %+%
  ggtitle(paste(base_titre, "(polar area diagram)"))
#name : coxcomb, 
#https://en.wikipedia.org/wiki/Pie_chart#Polar_area_diagram
#The polar area diagram is similar to a usual pie chart, except sectors are equal angles and differ rather in how far each sector extends from the center of the circle. The polar area diagram is used to plot cyclic phenomena (e.g., count of deaths by month). For example, if the count of deaths in each month for a year are to be plotted then there will be 12 sectors (one per month) all with the same angle of 30 degrees each. The radius of each sector would be proportional to the square root of the death count for the month, so the area of a sector represents the number of deaths in a month. If the death count in each month is subdivided by cause of death, it is possible to make multiple comparisons on one diagram, as is seen in the polar area diagram famously developed by Florence Nightingale.
```
\elandscape
\restoregeometry

\newgeometry{left=0cm, right=0cm, bottom=3cm}
\newpage
\blandscape

```{r star_graph, echo =F, cache = b_rad, fig.height=8.5, fig.width=8.5,fig.cap="carte de l'identité des neurones", out.width="1\\paperwidth"}
#radar
ggplot(melted_radar, aes(x = variable, y = value, col = variable)) %+% 
  facet_wrap( ~ id_neur, ncol = 30)  %+% 
  #geom_bar(stat="identity",position="dodge",width=.2) %+%
  geom_segment(aes(xend = variable, yend = 0), size = .2) %+%
  geom_point(size = .05) %+%
  ylim(0,1) %+%
  coord_polar(start = 0)  %+%
  #geom_text(aes(x = 1.5, y = 1, label = lab_rep), colour="black", size = 1, inherit.aes=F) %+%
  radar_theme %+%
  ggtitle(paste(base_titre, "(étoile)"))

```
\elandscape
\restoregeometry

\newgeometry{left=0cm, right=0cm, bottom=3cm}
\newpage
\blandscape

```{r radar_graph, echo =F, cache = b_rad, fig.height=8.5, fig.width=8.5,fig.cap="carte de l'identité des neurones", out.width="1\\paperwidth"}

#test
if(DEBUG){
test <- melted_radar %>% mutate(var_id = as.numeric(variable)) %>% filter(id_neur %in% c(1))

ggplot(test, aes(x = var_id, y = value, group = 1)) %+%
  facet_wrap( ~ id_neur, ncol = 30)  %+% 
  geom_polygon(fill = NA, col = "black") %+%
  geom_curve(aes(xend = lead(test$var_id, default = test$var_id[1]), yend = lead(test$value, default = test$value[1])), curvature = 0, color = "green") %+%
  coord_polar(start = -pi / nrow(test)) %+%
  #theme(panel.grid.minor=element_blank()) %+%
  #radar_theme %+%
  ggtitle(paste(base_titre, "(radar)"))
}

#radar
ggplot(melted_radar, aes(x = variable, y = value, group = 1)) %+% 
  facet_wrap( ~ id_neur, ncol = 30)  %+% 
  geom_polygon(fill = NA, color = "red") %+%
  coord_polar(start = 0)  %+%
  geom_text(aes(x = 1.5, y = 1, label = lab_rep), colour="black", size = 1, inherit.aes=F) %+%
  radar_theme %+%
  ggtitle(paste(base_titre, "(radar)"))

```
\elandscape
\restoregeometry

\newgeometry{left=0cm, right=0cm, bottom=3cm}
\newpage
\blandscape

```{r bar_grap, echo =F, cache = b_rad, fig.height=8.5, fig.width=8.5,fig.cap="carte de l'identité des neurones", out.width="1\\paperwidth"}
#bar
ggplot(melted_radar, aes(x = variable, y = value, fill = variable)) %+% 
  facet_wrap( ~ id_neur, ncol = 30)  %+% 
  geom_bar(stat="identity",position="dodge",width=.5) %+%
  ylim(0,1) %+%
  geom_text(aes(x = 1.5, y = 1, label = lab_rep), colour="black", size = 2, inherit.aes=F) %+%
  radar_theme %+%
  ggtitle(paste(base_titre, "(batons)"))

```
\elandscape
\restoregeometry

\newgeometry{left=0cm, right=0cm, bottom=3cm}
\newpage
\blandscape

```{r path_graph, echo =F, cache = b_rad, fig.height=8.5, fig.width=8.5,fig.cap="carte de l'identité des neurones", out.width="1\\paperwidth"}
#bar
ggplot(melted_radar, aes(x = variable, y = value, id_neur = 1)) %+% 
  facet_wrap( ~ id_neur, ncol = 30)  %+% 
   #scale_y_continuous(limits=c(0,0.07), breaks=seq(0,0.06,0.01)) %+%
  geom_line(aes(x= as.numeric(variable)),stat = "identity", col = "purple") %+%
  #geom_point(aes(x= as.numeric(variable)),stat = "identity", col = "black") %+%
  scale_x_continuous(expand=c(0,0), breaks=seq(0,360,10)) %+%
  #geom_text(aes(x = 1.5, y = 1, label = lab_rep), colour="black", size = 2, inherit.aes=F) %+%
  radar_theme %+%
  ggtitle(paste(base_titre, "(courbe)"))


```

\elandscape
\restoregeometry

## Graphiques des données captées par neurones

Les graphs suivantes nous permettent de représenter les expériences auxquelles appartiennent les données captées par chaque neurone. 

\newgeometry{left=5cm, right=0cm,bottom=3cm}
\newpage

```{r, echo =F, cache = T}
#==========================================#
## Carte des données captées par neurones ##
#==========================================#

#création d'un nouveau df montrant le nombre de données associées à chaque référent
#attention : certaines neurones peuvent ne pas avoir de données associées...

#on prend le df qui a servi au som
df_ref <- df_stat #inutile ??
df_ref <- df_stat #inutile ??
#on ajoute experience
df_ref$nom_experience <- df_selec$nom.experience
#et id_neurone
df_ref$id_neurone <- som$unit.classif
#on retire le superflu, on regroupe par pair id_neurone associé - nom_experience...
#...et on compte le nombre de données associé à chaque pair
df_count_neuro_expe <- df_ref %>% select(id_neurone, nom_experience) %>% 
  group_by(id_neurone, nom_experience) %>% summarise(count = n())

#on utilise tidyr::spread pour que chaque expe est sa colonne
expe_par_neurone <- df_count_neuro_expe %>% spread(nom_experience, count, fill = 0)

#reste algo précédent
#expe_par_neurone <- as.data.frame(with(df_ref, 
#                                       tapply(row.names(df_selec),
#                                              list(neurone=id_neurone,experience=nom.experience), 
#                                              length)))


#ajoutons les neurones manquants

#liste des neurones non présents
list_neuro_vid <- which(!seq(1:900) %in% as.numeric(expe_par_neurone$id_neurone))
nb_neuro_vid <- length(list_neuro_vid)
#df des neurones manquants
df_neuro_vid <- as.data.frame(matrix(nrow=nb_neuro_vid,ncol = ncol(expe_par_neurone)))
#prépa du rbind avec autre fdf
rownames(df_neuro_vid) <- list_neuro_vid
colnames(df_neuro_vid) <- colnames(expe_par_neurone)
df_neuro_vid$id_neurone <- list_neuro_vid
df_neuro_vid[is.na(df_neuro_vid)] <- 0
#bind_rows (not rbind !) & mis en ordre
expe_par_neurone <- bind_rows(expe_par_neurone,df_neuro_vid)
expe_par_neurone <- expe_par_neurone %>% arrange(id_neurone)

```

Nous commencons par associer chaque neurone à une couleur en fonction de l'expérience "majoritaire" (celle qui a le plus données captées par le référent)

```{r expe_maj, echo =F, cache = T}
##nom de l'experience la plus représentée par neurones
expe_major_par_neurone <- as.factor(colnames(expe_par_neurone[-1])[max.col(expe_par_neurone[-1])])
#put NA in line of neurone empty
expe_major_par_neurone[rowSums(expe_par_neurone)==0]<-NA
#test <- as.factor(rep(c("AB","CW","DA"),300))
#plot(som, type = "property", property = as.numeric(test), main="expérience majoritaire par neurone")

#representation graphique de l'expérience majoritaire par neurones :
plot(som, type = "property", property = as.numeric(expe_major_par_neurone), main="",  heatkey =F,palette.name=coolBlueHotRed)
text(x=som$grid$pts[,1],y=som$grid$pts[,2],labels=expe_major_par_neurone,cex = .5,font=2)
```

Graphique à réaliser avec ggplot...

\restoregeometry

La limite du précédent graphique est que l'on ne peut pas observer si plusieurs expériences ont été captées par un neurone. Cette information est pourtant forte intéressante dans l'optique de l'étiquetage car un neurone qui a capté plusieurs expériences a un grand intérêt : il montre que plusieurs expériences partagent des traits communs.

Le premier graphique nous indique pour chaque neurone le nombre de données captées pour chaque expérience. Chaque bâton indique le nombre total de données captées et chaque partie de bâton de couleur différente indique le nombre de données correspondant à une expérience (à chaque couleur est associée une expérience comme l'indique la légende.)

\newgeometry{left=0cm, right=0cm,bottom=3cm}
\newpage
\blandscape

```{r, echo =F, cache = T, fig.height=8.5, fig.width=8.5,fig.cap="carte des expériences par neurone ", out.width="1\\paperwidth"}
## Graph des répartitions entre expériences par neurones
nb_neur <- 900
nb_expe <- 8
base_rep <- 1:nb_neur
base_rep <- (nb_neur * 3):(nb_neur * 4)
rep <- rep("", nb_expe - 1)
lab_rep <- purrr::map(base_rep, function(ele) { c(ele, rep)}) %>% unlist()

# reprendre code pour recup expe_par_neurone
expe_par_neurone <- expe_par_neurone %>% head(nb_neur) 

#melted_expe_par_n <- melt(expe_par_neurone, id = "id_neurone") %>% 
#  group_by(id_neurone) %>% mutate(cumsum = cumsum(value)) %>% filter(variable != "id_neurone")

gathered_expe_par_n <- expe_par_neurone %>% gather(variable, value, -id_neurone) %>% 
  group_by(id_neurone) %>% mutate(cumsum = cumsum(value))

#gathered_expe_par_n %>% filter(id_neurone == 15)
  
expe_neuro_theme <-  theme(panel.margin.x = unit(0, "lines"), panel.margin.y = unit(0, "lines"), panel.border = element_rect(colour = no_frame, fill=NA, size=1),
        axis.text.x=element_text(size = 6), 
        axis.title.y=element_blank(), axis.text.y=element_text(size = 8), axis.ticks.y=element_blank(),
        strip.background = element_blank(), strip.text.x = element_blank(),
        legend.title = element_text(colour="black", size = 5,  face="bold"),
        legend.text = element_text(colour="black", size = 5),
        legend.key = element_rect(size = 1),
        title = element_text(color = "blue", size = 6, face = "bold"))

expe_neuro_theme2 <- theme(axis.text.y = element_text(size = 3, margin = margin(0, 0, 0, 0)))

ggplot(gathered_expe_par_n, aes(x = as.factor(id_neurone), y = value, fill = factor(variable))) %+% 
  geom_bar(stat = "identity") %+%
  #geom_text(aes(x = id_neur + .2, y = cumsum - 15, label = value), size = 3, colour = "black", check_overlap = TRUE) %+%
  geom_text(aes(x = id_neurone - 0, y = (cumsum + cumsum - value)/2, label = ifelse(value != 0, as.character(variable), "")), size = 3, colour = "black", check_overlap = T) %+%
  expe_neuro_theme %+%
  ggtitle("expériences captées")

```
\elandscape
\restoregeometry

Cette carte est similaire à la précédente mais la hauteur de chaque bâton est fixée à une même valeur. Cette carte permet donc d'observer la *répartition* des données associées à chaque neurone indépendamment de leur nombre.

\newgeometry{left=0cm, right=0cm,bottom=3cm}
\newpage
\blandscape
```{r, echo =F, cache = T, fig.height=8.5, fig.width=10.5,fig.cap="carte de la répartition des expériences par neurone", out.width="1\\paperwidth"}
ggplot(gathered_expe_par_n, aes(x = id_neurone, y = value, fill = factor(variable))) %+% 
  geom_bar(stat = "identity", position = "fill") %+%
  #geom_text(aes(y = cumsum - 15, label = value), colour = "black") %+%
  expe_neuro_theme %+%
  ggtitle("expériences captées")

```
\elandscape
\restoregeometry

\newgeometry{left=0cm, right=0cm,bottom=3cm}
\newpage
\blandscape
```{r, echo =F, cache = T, fig.height=8.5, fig.width=8.5,fig.cap="carte des données par expérience", out.width="1\\paperwidth"}
expe_neuro_theme3 <-  theme(panel.margin.x = unit(0, "lines"), 
                            panel.margin.y = unit(0, "lines"), 
                            panel.border = element_rect(colour = no_frame, fill=NA, size=0),
        axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(),
        axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank(),
        strip.background = element_blank(), strip.text.x = element_blank(),
        legend.title = element_text(colour="black", size = 5,  face="bold"),
        legend.text = element_text(colour="black", size = 5),
        legend.key = element_rect(size = 1),
        title = element_text(color = "blue", size = 6, face = "bold"))

if (DEBUG) {
  test2 <- gathered_expe_par_n %>% filter(id_neurone %in% c(1:20))
  ggplot(test2, aes(x = variable, y = value, fill = variable)) %+% 
  facet_wrap( ~ id_neurone, ncol = 30, scales = "free")  %+% 
  geom_bar(stat="identity") %+%
  expe_neuro_theme3 %+%
  ggtitle("expériences captées")
}
#regroupement par neurones des exper
ggplot(gathered_expe_par_n, aes(x = variable, y = value, fill = variable)) %+% 
  facet_wrap( ~ id_neurone, ncol = 30, scales = "free")  %+% 
  geom_bar(stat="identity") %+%
  expe_neuro_theme3 %+%
  ggtitle("expériences captées")

```
\elandscape
\restoregeometry

##Carte des temporalités captées par neurones

Une dimension importante qui n'apparaît pas dans les cartes est le temps. Nous avons à faire avec des séries temporelles pour chaque variable et il est intéressant de mettre en relation l'évolution

\newgeometry{left=0cm, right=0cm,bottom=3cm}
\newpage
\blandscape

```{r, echo =F, cache = T, fig.height=8.5, fig.width=8.5,fig.cap="carte des neurones dans leur plan", out.width="1\\paperwidth"}
#on prend le df général
df_sec <- as.data.table(df_selec)
#on crée une var de facteur par secondes (arbitraire ??)
df_sec$one_sec_elapsed <- df_selec$tps.ecoule %>% round(digits = 0) %>% factor()
df_sec$five_sec_elapsed <- df_selec$tps.ecoule %>% `/`(5)  %>% round(digits = 0) %>% factor()
#on ajoute id_neurone
df_sec$id_neurone <- som$unit.classif

## Table of the time per neurones

#on retire les expe qui finissent pas 2 ou 3
#df_sec <- df_sec %>% filter(!grepl("*[2|3]",nom.experience))
#on retire le superflu, on regroupe par pair id_neurone - sec_elapsed...
#...et on compte le nombre de données associé à chaque pair
df_neuro_sec <- df_sec %>% select(id_neurone, one_sec_elapsed, nom.experience) 
df_neuro_5sec <- df_sec %>% select(id_neurone, five_sec_elapsed, nom.experience) 
df_count_neuro_1sec <- df_neuro_sec %>% 
  group_by(id_neurone, one_sec_elapsed, nom.experience) %>% summarise(count = n())
df_count_neuro_5sec <- df_neuro_5sec %>% 
  group_by(id_neurone, five_sec_elapsed, nom.experience) %>% summarise(count = n())

#on utilise tidyr::spread pour que chaque expe est sa colonne
expe_par_sec <- df_count_neuro_1sec %>% spread(nom.experience, count, fill = 0)
expe_par_5sec <- df_count_neuro_5sec %>% spread(nom.experience, count, fill = 0)

## table of the neurones graphs according to time
dt_neur_coord <- data.table(id_neurones = 1:900, x = som$grid$pts[,1], y = som$grid$pts[,2])

#create a data table that for each experience shows the neurone path in the data and the time spent in each neurone
chg_neur <- df_sec$id_neurone != lag(df_sec$id_neurone) | df_sec$nom.experience != lag(df_sec$nom.experience) 
chg_neur[1] <- T
path_neur <- df_sec$id_neurone[chg_neur]
nom_expe <- df_sec$nom.experience[chg_neur]
#no change : 1 as long as the referent is not changing
no_chg <- as.numeric(!chg_neur)
#reduce the no change vec into a vector that counts the length of each series of no change  
nb_data <- no_chg %>% purrr::reduce( function(prev, cur) { if(cur == 1) {prev[length(prev)] <- prev[length(prev)] + 1 ; prev } else{ prev[length(prev)+1] <- 1; prev }}, 1)
#creata a dt
dt_path_neur <- data.table(path_neur, nom_expe, nb_data)
dt_path_neur <- bind_cols(dt_path_neur,as.data.frame(dt_neur_coord[dt_path_neur$path_neur,.(x,y)]))
#next neurone coordinates
#let first of each experience at na ??
new_expe <- dt_path_neur$nom_expe != lag(dt_path_neur$nom_expe)
dt_path_neur$xend <- lag(dt_path_neur$x, default = dt_path_neur$x[1])
dt_path_neur$yend <- lag(dt_path_neur$y, default = dt_path_neur$y[1])
```
\elandscape
\restoregeometry

\newgeometry{left=0cm, right=0cm,bottom=3cm}
\newpage
\blandscape
```{r, echo =F, cache = T, fig.height=8.5, fig.width=8.5,fig.cap="carte des neurones dans leur plan", out.width="1\\paperwidth"}
#new graph of the neurones
ggplot(dt_neur_coord, aes(x = x, y = y)) + geom_point( col = "blue", shape = 21)
```
\elandscape
\restoregeometry

\newgeometry{left=0cm, right=0cm,bottom=3cm}
\newpage
\blandscape
```{r neur_exp_size, echo =F, cache = T, fig.height=8.5, fig.width=8.5,fig.cap="carte des neurones en fonction du nombre de données captées par expérience", out.width="1\\paperwidth"}
dt_path_neur_ord <- dt_path_neur %>% dplyr::arrange(desc(nb_data))
ggplot(dt_path_neur_ord, aes(x = x, y = y)) %+% 
  geom_point(aes(col = nom_expe, size = nb_data), alpha = 0.5) 

```
\elandscape
\restoregeometry

\newgeometry{left=0cm, right=0cm,bottom=3cm}
\newpage
\blandscape
```{r neur_exp_jit, echo =F, cache = T, fig.height=8.5, fig.width=8.5,fig.cap="carte des neurones par expérience avec \"jitter\"", out.width="1\\paperwidth"}
#graph with neurones color given according to the experience attached to it (add a little jitter to help with overlap)
ggplot(dt_path_neur_ord, aes(x = x, y = y)) %+% geom_jitter(aes(col = nom_expe), width = 0.5, height = 0.5, alpha = 0.4) 
```
\elandscape
\restoregeometry

\newgeometry{left=0cm, right=0cm,bottom=3cm}
\newpage
\blandscape
```{r neur_exp_jit_ord, echo =F, cache = T, fig.height=8.5, fig.width=8.5,fig.cap="carte des neurones par expérience avec \"jitter\" et taille", out.width="1\\paperwidth"}
ggplot(dt_path_neur_ord, aes(x = x, y = y, size = nb_data)) %+% geom_jitter(aes(col = nom_expe), width = 0.5, height = 0.5, alpha = 0.4) 
```
\elandscape
\restoregeometry

\newgeometry{left=0cm, right=0cm,bottom=3cm}
\newpage
\blandscape
```{r, echo =F, cache = T, fig.height=8.5, fig.width=8.5,fig.cap="carte du déplacement dans les neurones pour l'expérience AB", out.width="1\\paperwidth"}
test_AB <- dt_path_neur %>% filter(nom_expe == "AB") %>% dplyr::mutate(elapsed_time = cumsum(nb_data)) %>% data.table

ggplot(test_AB, aes(x = x, y = y)) %+% 
  geom_point(col = "darkgrey")  %+%
  geom_segment(aes(xend = xend, yend = yend, col = elapsed_time), alpha = .5, arrow = arrow(length = unit(0.02, "npc"))) %+%
  scale_color_gradient2(low = "blue", high = "red")

```
\elandscape
\restoregeometry

\newgeometry{left=0cm, right=0cm,bottom=3cm}
\newpage
\blandscape
```{r, echo =F, cache = T, fig.height=8.5, fig.width=8.5,fig.cap="carte du déplacement dans les neurones pour l'expérience AB", out.width="1\\paperwidth"}
#fonction to print path for one expe in neurones graph
reseau_par_exp <- function(nom_exp) {
  
dt_exp <- dt_path_neur %>% filter(nom_expe == nom_exp) %>% dplyr::mutate(elapsed_time = cumsum(nb_data)) %>% data.table

gg <- ggplot(dt_exp, aes(x = x, y = y)) %+% 
  geom_point(col = "darkgrey")  %+%
  geom_segment(aes(xend = xend, yend = yend, col = elapsed_time), alpha = .5, arrow = arrow(length = unit(0.02, "npc"))) %+%
  scale_color_gradient2(low = "blue", high = "red") %+%
  ggtitle(paste("graph de l'experience", nom_exp))
print(gg)
}
purrr::walk(list.expe.selec, reseau_par_exp)

```
\elandscape
\restoregeometry
\newgeometry{left=0cm, right=0cm,bottom=3cm}
\newpage
\blandscape
```{r, echo =F, cache = T, fig.height=8.5, fig.width=8.5,fig.cap="carte des référents par expérience", out.width="1\\paperwidth"}
dt_path_neur <- dt_path_neur %>% group_by(nom_expe) %>% mutate(elapsed_time = cumsum(nb_data)) %>% data.table() 

cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

ggplot(dt_path_neur, aes(x = x, y = y)) %+%
  ggplot2::facet_wrap(facets =  ~ nom_expe) %+% 
  scale_color_manual(values = cbPalette) %+%
  geom_point(aes(col = nom_expe)) 

```
\elandscape
\restoregeometry

\newgeometry{left=0cm, right=0cm,bottom=3cm}
\newpage
\blandscape

```{r, echo=F, cache = T, fig.height=8.5, fig.width=8.5, out.width="1\\paperwidth"}

graph_path_neurons <- function(df) {
  #colors & theme
  cbPalette2 <- c("#F00000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
  simple_theme <- theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
                 panel.background = element_blank(), axis.line = element_line(colour = "black"))
  
  gg <-  ggplot(df, aes(x = x, y = y)) %+%
    facet_wrap(facets =  ~ nom_expe) %+% 
    geom_segment(aes(xend = xend, yend = yend, col = elapsed_time), alpha = .5, arrow = arrow(length = unit(0.05, "npc"))) %+% 
    scale_color_gradient2(low = "blue", high = "red") %+%
    geom_point(aes(fill = nom_expe, size = nb_data), shape = 21) %+% 
    scale_fill_manual(values = cbPalette2) %+%
    simple_theme %+%
    ggtitle("déplacement des données entre les référents")
  print(gg)
}

dt_path_short <- dt_path_neur %>% filter(elapsed_time < 10000)
graph_path_neurons(dt_path_short)
```
\elandscape
\restoregeometry

\newgeometry{left=0cm, right=0cm,bottom=3cm}
\newpage
\blandscape

```{r, echo=F, cache = T, fig.height=8.5, fig.width=8.5, out.width="1\\paperwidth"}

dt_path_short2 <- dt_path_neur %>% filter(elapsed_time >= 10000 & elapsed_time < 20000)
graph_path_neurons(dt_path_short2)
```
\elandscape
\restoregeometry

\newgeometry{left=0cm, right=0cm,bottom=3cm}
\newpage
\blandscape
```{r, echo=F, cache = T, fig.height=8.5, fig.width=8.5, out.width="1\\paperwidth"}

dt_path_short3 <- dt_path_neur %>% filter(elapsed_time >= 20000 & elapsed_time < 30000)
graph_path_neurons(dt_path_short3)
```

\elandscape
\restoregeometry

\newgeometry{left=0cm, right=0cm,bottom=3cm}
\newpage
\blandscape

```{r, echo=F, cache = T, fig.height=8.5, fig.width=8.5, out.width="1\\paperwidth"}
dt_path_short4 <- dt_path_neur %>% filter(elapsed_time >= 30000 & elapsed_time < 40000)
graph_path_neurons(dt_path_short4)
```

\elandscape
\restoregeometry
